{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3904978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import fileinput\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064357f9",
   "metadata": {},
   "source": [
    "## 인자값 입력\n",
    "\n",
    "### 1) 병합할 파일들이 있는 디렉토리 경로\n",
    "### 2) 출력파일 디렉토리 경로\n",
    "### 3) 병합할 파일의 시간 필드명\n",
    "### 4) 병합할 환경데이터 파일 디렉토리 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59ac9388",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_input_path = './data'\n",
    "file_output_path = './out'\n",
    "date_time = 'coll_dt'\n",
    "target_data_info = \"['weather','./env_data/weather_seoul/'],['traffic','..env_data/traffic_volume/'],['air','./env_data/air_pollution_gangnam/']\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "105a0a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printProgressBar(iteration, total, prefix = 'Progress', suffix = 'Complete',\\\n",
    "                      decimals = 1, length = 50, fill = '█'): \n",
    "    # 작업의 진행상황을 표시\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print('\\r%s |%s| %s%% %s' %(prefix, bar, percent, suffix), end='\\r')\n",
    "    sys.stdout.flush()\n",
    "    if iteration == total:\n",
    "        print()\n",
    "\n",
    "def recursive_search_dir(_nowDir, _filelist):\n",
    "    dir_list = []  # 현재 디렉토리의 서브디렉토리가 담길 list\n",
    "    try:\n",
    "        f_list = os.listdir(_nowDir)\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\n\"+_nowDir)\n",
    "        print(\"\\n(병합 대상 파일이 존재하지 않습니다.)\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    for fname in f_list:\n",
    "        if os.path.isdir(_nowDir + \"/\" + fname):\n",
    "            dir_list.append(_nowDir + \"/\" + fname)\n",
    "        elif os.path.isfile(_nowDir + \"/\" + fname):\n",
    "            file_extension = os.path.splitext(fname)[1]\n",
    "            if file_extension == \".csv\" or file_extension == \".CSV\":  # csv\n",
    "                _filelist.append(_nowDir + \"/\" + fname)\n",
    "\n",
    "    for toDir in dir_list:\n",
    "        recursive_search_dir(toDir, _filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe9bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging(merged_file_full_path, csv_file, target_data_info, date_time):\n",
    "    df = pd.read_csv(csv_file, low_memory=False)\n",
    "\n",
    "    # 병합할 환경데이터 카테고리 목록을 dict로 모두 저장 (index도 함께 저장)\n",
    "    category = dict()\n",
    "    for i in range(len(target_data_info)):\n",
    "        category[target_data_info[i][0]] = i\n",
    "\n",
    "    # 필드 병합할 때, 이미 불러온 데이터는 dictionary에 저장 (속도 향상 위해)\n",
    "    weather_cache = dict()\n",
    "    traffic_cache = dict()\n",
    "    air_cache = dict()\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        # YYYY mm dd HH 순서일 때\n",
    "        date_time_digit = re.sub('-|:|/| ', '', str(df[date_time].iloc[i]))   # '-', ':', '/', ' ' 제거하고, 순수 숫자만 남김\n",
    "        ref_date = date_time_digit[:8]\n",
    "        ref_time = int(date_time_digit[8:10])\n",
    "\n",
    "        # 날씨데이터를 병합할 경우\n",
    "        if 'weather' in category.keys():\n",
    "            weather_key = ref_date + str(ref_time) # 이미 받아온 값인지 확인하기 위한 key값 (날짜/시간)\n",
    "\n",
    "            if weather_key in weather_cache:\n",
    "                weather_value = weather_cache[weather_key]\n",
    "            else:\n",
    "                weather_file = target_data_info[category['weather']][1] + '/' + ref_date + '.json'\n",
    "                try:\n",
    "                    with open(weather_file, 'r') as file:\n",
    "                        data = json.load(file)\n",
    "\n",
    "                        # print(\"관측지점ID:\", data[ref_time]['stnId'])\n",
    "                        # print(\"기온(˚C):\", data[ref_time]['ta'])\n",
    "                        # print(\"풍속(m/s):\", data[ref_time]['ws'])\n",
    "                        # print(\"습도(%):\", data[ref_time]['hm'])\n",
    "                        # print(\"강수량(mm):\", data[ref_time]['rn'])\n",
    "                        # print(\"적설(cm):\", data[ref_time]['dsnw'])\n",
    "\n",
    "                        weather_value = [('weather_station_ID', data[ref_time]['stnId']), ('temperature', data[ref_time]['ta']), ('wind_speed', data[ref_time]['ws']), ('humidity', data[ref_time]['hm']), ('rainfall', data[ref_time]['rn']), ('snowfall', data[ref_time]['dsnw'])]\n",
    "\n",
    "                # 해당 날짜의 환경데이터 파일이 없을 경우, NaN값으로 입력\n",
    "                except FileNotFoundError:\n",
    "                    weather_value = [('weather_station_ID', np.nan), ('temperature', np.nan), ('wind_speed', np.nan), ('humidity', np.nan), ('rainfall', np.nan), ('snowfall', np.nan)]\n",
    "\n",
    "                # 불러온 환경데이터 값을 캐시에 저장 (속도 향상 위해)\n",
    "                weather_cache[weather_key] = weather_value\n",
    "            \n",
    "            for value in weather_value:\n",
    "                if i == 0:  # 날씨 값을 넣기 위해, 빈 컬럼 추가\n",
    "                    df.insert(loc=len(df.columns), column=value[0], value='')\n",
    "                df.loc[i, value[0]] = value[1]   # 날씨 값을 새로운 컬럼에 추가\n",
    "\n",
    "        # 교통데이터를 병합할 경우\n",
    "        if 'traffic' in category.keys():\n",
    "            traffic_key = ref_date # 이미 받아온 값인지 확인하기 위한 key값 (날짜)\n",
    "\n",
    "            if traffic_key in traffic_cache:\n",
    "                traffic_value = traffic_cache[traffic_key]\n",
    "            else:\n",
    "                traffic_file = target_data_info[category['traffic']][1] + '/' + ref_date + '.json'\n",
    "                try:\n",
    "                    with open(traffic_file, 'r') as file:\n",
    "                        data = json.load(file)\n",
    "\n",
    "                        # print(\"교통량:\", data[0]['trafficVolumn'])\n",
    "\n",
    "                        traffic_value = [('traffic_volume', data[0]['trafficVolumn'])]\n",
    "\n",
    "                # 해당 날짜의 환경데이터 파일이 없을 경우, NaN값으로 입력\n",
    "                except FileNotFoundError:\n",
    "                    traffic_value = [('traffic_volume', np.nan)]\n",
    "\n",
    "                # 불러온 환경데이터 값을 캐시에 저장 (속도 향상 위해)\n",
    "                traffic_cache[traffic_key] = traffic_value\n",
    "\n",
    "            for value in traffic_value:\n",
    "                if i == 0:  # 교통량 값을 넣기 위해, 빈 컬럼 추가\n",
    "                    df.insert(loc=len(df.columns), column=value[0], value='')\n",
    "                df.loc[i, value[0]] = value[1]   # 교통량 값을 새로운 컬럼에 추가\n",
    "\n",
    "        # 대기오염 데이터를 병합할 경우\n",
    "        if 'air' in category.keys():\n",
    "            air_key = ref_date # 이미 받아온 값인지 확인하기 위한 key값 (날짜)\n",
    "\n",
    "            if air_key in air_cache:\n",
    "                air_value = air_cache[air_key]\n",
    "            else:\n",
    "                air_file = target_data_info[category['air']][1] + '/' + ref_date + '.json'\n",
    "                try:\n",
    "                    with open(air_file, 'r') as file:\n",
    "                        data = json.load(file)\n",
    "\n",
    "                        # print(\"일산화탄소 평균농도:\", data[0]['coValue'])\n",
    "                        # print(\"이산화질소 평균농도:\", data[0]['no2Value'])\n",
    "                        # print(\"오존 평균농도:\", data[0]['o3Value'])\n",
    "                        # print(\"미세먼지(PM10) 평균농도:\", data[0]['pm10Value'])\n",
    "                        # print(\"미세먼지(PM25) 평균농도:\", data[0]['pm25Value'])\n",
    "                        # print(\"아황산가스 평균농도:\", data[0]['so2Value'])\n",
    "\n",
    "                        air_value = [('air_co', data[0]['coValue']), ('air_no2', data[0]['no2Value']), ('air_o3', data[0]['o3Value']), ('air_pm10', data[0]['pm10Value']), ('air_pm25', data[0]['pm25Value']), ('air_so2', data[0]['so2Value'])]\n",
    "\n",
    "                # 해당 날짜의 환경데이터 파일이 없을 경우, NaN값으로 입력\n",
    "                except FileNotFoundError:\n",
    "                    air_value = [('air_co', np.nan), ('air_no2', np.nan), ('air_o3', np.nan), ('air_pm10', np.nan), ('air_pm25', np.nan), ('air_so2', np.nan)]\n",
    "\n",
    "                # 불러온 환경데이터 값을 캐시에 저장 (속도 향상 위해)\n",
    "                air_cache[air_key] = air_value\n",
    "\n",
    "            for value in air_value:\n",
    "                if i == 0:  # 대기오염 값을 넣기 위해, 빈 컬럼 추가\n",
    "                    df.insert(loc=len(df.columns), column=value[0], value='')\n",
    "                df.loc[i, value[0]] = value[1]   # 대기오염 값을 새로운 컬럼에 추가\n",
    "\n",
    "        # 추후 다른 환경데이터 병합 시, 여기에 코드 추가\n",
    "        if 'blah_blah_blah' in category:\n",
    "            return 0\n",
    "\n",
    "    # 병합된 df를 csv 파일에 저장\n",
    "    df.to_csv(merged_file_full_path, index=False)\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a227af8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input Files Dir. location =  ./data\n",
      " Additional Files Info. =  (['weather', './env_data/weather_seoul'], ['traffic', '..env_data/traffic_volume'], ['air', './env_data/air_pollution_gangnam'])\n",
      " Output Files Dir. location =  ./out\n",
      "\n",
      "======================================================\n",
      "필드 병합 시작\n",
      "======================================================\n",
      "CSV 파일 목록 불러오는 중..\n",
      "총 CSV 파일 수 : 35\n",
      "\n",
      "필드 병합 중..\n",
      "Progress |██████████████████████████████████████████████████| 100.0% Complete\n",
      "\n",
      "기존 병합 처리된 파일 수 : 0\n",
      "새로 병합 완료한 파일 수 : 1\n",
      "total running time : 8.36 sec\n"
     ]
    }
   ],
   "source": [
    "# 문자열을 list로 변환\n",
    "target_data_info = eval(target_data_info)\n",
    "\n",
    "\n",
    "if file_input_path[-1] == '/':\n",
    "    file_input_path = file_input_path[:-1]\n",
    "\n",
    "for info in target_data_info:\n",
    "    if info[1][-1] == '/':\n",
    "        info[1] = info[1][:-1]\n",
    "\n",
    "\n",
    "print (\" Input Files Dir. location = \", file_input_path)\n",
    "print (\" Additional Files Info. = \", target_data_info)\n",
    "print (\" Output Files Dir. location = \", file_output_path)\n",
    "csv_list = []\n",
    "\n",
    "print('\\n======================================================')\n",
    "print('필드 병합 시작')\n",
    "print('======================================================')\n",
    "print('CSV 파일 목록 불러오는 중..')\n",
    "recursive_search_dir(file_input_path, csv_list)\n",
    "\n",
    "print('총 CSV 파일 수 : {}'.format(len(csv_list)))\n",
    "\n",
    "proc_start_time = time.time()\n",
    "\n",
    "exist_cnt = 0\n",
    "print('\\n필드 병합 중..')\n",
    "progress_cnt=0\n",
    "result_cnt=0\n",
    "for csv_file in csv_list:\n",
    "    printProgressBar(progress_cnt, len(csv_list))\n",
    "    # 병합 파일을 저장할 경로\n",
    "    merged_file_name = csv_file.replace(file_input_path, '').split('/')[-1]   # \"OOOOO.csv\"\n",
    "    merged_file_dir = file_output_path + csv_file.replace(file_input_path, '').replace(merged_file_name, '')\n",
    "\n",
    "    if not os.path.isdir(merged_file_dir):\n",
    "        os.makedirs(merged_file_dir)\n",
    "\n",
    "    merged_file_full_path = merged_file_dir + merged_file_name\n",
    "\n",
    "    # 병합 파일명이 이미 존재할 경우, 통과\n",
    "    if os.path.isfile(merged_file_full_path):\n",
    "        exist_cnt += 1\n",
    "        continue\n",
    "\n",
    "    result_cnt += merging(merged_file_full_path, csv_file, target_data_info, date_time)\n",
    "    progress_cnt += 1\n",
    "printProgressBar(progress_cnt, len(csv_list))\n",
    "\n",
    "    # time.sleep(0.001) # CPU 부하 줄이기 위함\n",
    "\n",
    "print('병합 완료한 파일 수 : {}'.format(result_cnt))\n",
    "print('total running time : {:.2f} sec'.format(time.time()-proc_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91a7a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
